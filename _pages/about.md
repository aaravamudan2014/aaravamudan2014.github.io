---
permalink: /
title: "academicpages is a ready-to-fork GitHub Pages template for academic personal websites"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
Welcome to my website! 

# About me

My name is Akshay Aravamudan. I am currently a third year PhD student in Computer Engineering at Florida Institute of Technology. Over the course of my academic career I was fortunate to have worked on several interesting projects with equally interesting people. My main research is in the utility of Stochastic point processes in the context of big data to derive  valuable insights. 

I am also working with CADAS on a project whose focus is AI on the edge. This has us developing deep learning models with fewer parameters while maintaining its performance. I've been working on this project for a year and am a co-author in two papers published in MILCOM and WF-IoT respectively. 

Finally, I am also working in conjunction with the mechanical engineering department in exploring the use of machine learning techniques 

# Research Interests

## Stochastic point processes

In layman's terms, a Stochastic point processes is used to model events on an axis. We just happen to focus on the time axis (Temporal Stochastci Point Process). The realm (in literature) of stochastic temporal point processes is quite vast and has seen decades of incremental yet seminal works in the area. To this end, our group focuses on several aspects of these processes. My Masters thesis explored the use of survival processes (temporal point processes with single realizations) for the spread of information. Lately we have been exploring improvements on this model by considering a split-population setting wherein individual users do not necessarily participate in a cascade. 

Of late, our group has been looking into Hawkes processes and their moments for effective online learning. Additionally, under the context of Hawkes processes, we attempt to evaluate useful metrics for the determinance of causality.


## Super-resolution

While the field of super-resolution has seen vast improvements over the past several years, they fail to adequately generalize to other tasks that operate under a similar modus operandi. For instance, Our group in conjunction with folks from the Mechanical Engineering department (Dr. Efthymios Nikolopoulos and Zimeena Rasheed) have been working to develop a deep learning based super-resolution model to downscale (upsample) Flood Inundation Maps (FIMs). Disparate to traditional inputs to super-resolution models, the input pixels contain a water fraction (approximentely the number of pixels inundadated in the high resolution FIM).

Our preliminary results indicate the custom constructed Residual Dense Networks (RDNs) tend to have superior performance compared to traditional and deep learning based super-resolution models. Additionally, our investigation into the utility of topographic features (such as horizontal and vertical distance to nearest drainage). This work was published as an extended abstract at AGU 2021. We are also currently working on a manuscript for an upcoming journal submission. 

## Machine learning on the edge

Since 2021, I have been working with CADAS (Center of Advanced Data Analytic Systems) on a project that aims at implementing and developing effective and efficient models at the edge. This involves developing models that retain high semblance of performance while working under severely resource constrained settings. So far, we have published two works under this project. One was published in WF-IoT and the other was published in MILCOM.




